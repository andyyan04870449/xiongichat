# 01 - 資料庫架構設計文件

## 快速恢復指南
如果你忘記了這個模組，記住：這是整個系統的資料基礎，負責儲存對話、訊息、個案檔案，並支援市府平台的增量同步拉取。

## 核心技術棧
- PostgreSQL 15+ (主資料庫)
- pgvector extension (向量檢索)
- Redis (快取與 Rate Limiting)

## 資料庫連線設定
```python
# .env 檔案
DATABASE_URL=postgresql://user:pass@localhost:5432/xiongichat
REDIS_URL=redis://localhost:6379/0

# database.py
from sqlalchemy import create_engine
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker

# 異步引擎 (主要使用)
async_engine = create_async_engine(
    DATABASE_URL,
    pool_size=20,
    max_overflow=40,
    pool_pre_ping=True,
    echo=False
)

AsyncSessionLocal = sessionmaker(
    async_engine,
    class_=AsyncSession,
    expire_on_commit=False
)
```

## 核心資料表設計

### 1. cases 表 (個案檔案)
```sql
CREATE TABLE cases (
    user_id TEXT PRIMARY KEY,
    nickname TEXT,
    lang TEXT DEFAULT 'zh-TW',
    stage TEXT CHECK (stage IN ('assessment', 'treatment', 'recovery')),
    goals JSONB DEFAULT '[]',
    created_at TIMESTAMP NOT NULL DEFAULT now(),
    updated_at TIMESTAMP NOT NULL DEFAULT now()
);

-- 觸發器：自動更新 updated_at
CREATE OR REPLACE FUNCTION update_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = now();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER update_cases_updated_at
BEFORE UPDATE ON cases
FOR EACH ROW EXECUTE FUNCTION update_updated_at();
```

### 2. conversations 表 (會話)
```sql
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id TEXT NOT NULL REFERENCES cases(user_id),
    started_at TIMESTAMP NOT NULL DEFAULT now(),
    ended_at TIMESTAMP,
    last_message_at TIMESTAMP,
    metadata JSONB DEFAULT '{}',
    updated_at TIMESTAMP NOT NULL DEFAULT now()
);

CREATE INDEX idx_conv_user ON conversations(user_id);
CREATE INDEX idx_conv_updated ON conversations(updated_at DESC);
CREATE INDEX idx_conv_last_msg ON conversations(last_message_at DESC NULLS LAST);
```

### 3. conversation_messages 表 (訊息)
```sql
CREATE TABLE conversation_messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL REFERENCES conversations(id) ON DELETE CASCADE,
    role TEXT NOT NULL CHECK (role IN ('user','assistant','system')),
    content TEXT NOT NULL,  -- 原文 (應用層加密)
    content_redacted TEXT,  -- 脫敏版本
    content_encrypted BYTEA,  -- 加密後的原文 (選用)
    risk_level TEXT CHECK (risk_level IN ('NONE','LOW','MEDIUM','HIGH','IMMINENT')),
    risk_categories TEXT[] DEFAULT '{}',
    risk_evidence JSONB,
    rag_sources JSONB,  -- [{title, source, date, score}]
    profile_snapshot JSONB,  -- 回覆時的個案狀態快照
    token_count INTEGER,
    created_at TIMESTAMP NOT NULL DEFAULT now(),
    updated_at TIMESTAMP NOT NULL DEFAULT now()
);

-- 複合索引優化查詢
CREATE INDEX idx_msg_conv_time ON conversation_messages(conversation_id, created_at);
CREATE INDEX idx_msg_updated ON conversation_messages(updated_at DESC);
CREATE INDEX idx_msg_risk ON conversation_messages(risk_level) WHERE risk_level != 'NONE';

-- 分區 (按月)
CREATE TABLE conversation_messages_2025_01 PARTITION OF conversation_messages
FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
```

### 4. sync_bookmarks 表 (同步書籤)
```sql
CREATE TABLE sync_bookmarks (
    consumer_id TEXT PRIMARY KEY,  -- e.g., 'kao-main-platform'
    last_conversation_cursor TEXT,
    last_message_cursor TEXT,
    last_sync_at TIMESTAMP,
    sync_stats JSONB DEFAULT '{}',  -- {total_synced, errors, etc}
    updated_at TIMESTAMP NOT NULL DEFAULT now()
);
```

### 5. rag_documents 表 (知識庫文件)
```sql
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE rag_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title TEXT NOT NULL,
    content TEXT NOT NULL,
    source TEXT,  -- URL 或來源標識
    category TEXT,  -- medical, legal, service, etc
    lang TEXT DEFAULT 'zh-TW',
    embedding vector(1536),  -- OpenAI embedding dimension
    metadata JSONB DEFAULT '{}',
    published_date DATE,
    created_at TIMESTAMP NOT NULL DEFAULT now(),
    updated_at TIMESTAMP NOT NULL DEFAULT now()
);

-- 向量索引 (使用 ivfflat)
CREATE INDEX idx_rag_embedding ON rag_documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- 文字搜尋索引
CREATE INDEX idx_rag_content_gin ON rag_documents 
USING gin(to_tsvector('chinese', content));
```

## SQLAlchemy Models

```python
# models.py
from sqlalchemy import Column, String, Text, DateTime, JSON, ForeignKey, ARRAY, LargeBinary
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
from pgvector.sqlalchemy import Vector
import uuid

Base = declarative_base()

class Case(Base):
    __tablename__ = "cases"
    
    user_id = Column(String, primary_key=True)
    nickname = Column(String)
    lang = Column(String, default="zh-TW")
    stage = Column(String)
    goals = Column(JSON, default=list)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

class Conversation(Base):
    __tablename__ = "conversations"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(String, ForeignKey("cases.user_id"), nullable=False)
    started_at = Column(DateTime(timezone=True), server_default=func.now())
    ended_at = Column(DateTime(timezone=True))
    last_message_at = Column(DateTime(timezone=True))
    metadata = Column(JSON, default=dict)
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

class ConversationMessage(Base):
    __tablename__ = "conversation_messages"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    conversation_id = Column(UUID(as_uuid=True), ForeignKey("conversations.id"), nullable=False)
    role = Column(String, nullable=False)
    content = Column(Text, nullable=False)
    content_redacted = Column(Text)
    content_encrypted = Column(LargeBinary)
    risk_level = Column(String)
    risk_categories = Column(ARRAY(String), default=list)
    risk_evidence = Column(JSON)
    rag_sources = Column(JSON)
    profile_snapshot = Column(JSON)
    token_count = Column(Integer)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now(), onupdate=func.now())

class RagDocument(Base):
    __tablename__ = "rag_documents"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    title = Column(Text, nullable=False)
    content = Column(Text, nullable=False)
    source = Column(Text)
    category = Column(String)
    lang = Column(String, default="zh-TW")
    embedding = Column(Vector(1536))  # pgvector type
    metadata = Column(JSON, default=dict)
    published_date = Column(Date)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now())
```

## 資料庫操作助手

```python
# db_helper.py
from contextlib import asynccontextmanager
from typing import Optional, List, Dict
from datetime import datetime
from sqlalchemy import select, and_, or_
from sqlalchemy.ext.asyncio import AsyncSession

class DatabaseHelper:
    
    @asynccontextmanager
    async def get_session(self):
        async with AsyncSessionLocal() as session:
            try:
                yield session
                await session.commit()
            except Exception:
                await session.rollback()
                raise
    
    async def get_or_create_conversation(
        self, 
        user_id: str,
        conversation_id: Optional[str] = None
    ) -> str:
        """取得或建立會話"""
        async with self.get_session() as session:
            if conversation_id:
                result = await session.execute(
                    select(Conversation).where(
                        Conversation.id == conversation_id
                    )
                )
                conv = result.scalar_one_or_none()
                if conv:
                    return str(conv.id)
            
            # 建立新會話
            new_conv = Conversation(user_id=user_id)
            session.add(new_conv)
            await session.flush()
            return str(new_conv.id)
    
    async def save_message_pair(
        self,
        conversation_id: str,
        user_content: str,
        assistant_content: str,
        risk_info: Dict,
        rag_sources: List[Dict],
        profile_snapshot: Dict
    ):
        """儲存使用者訊息與助理回覆"""
        async with self.get_session() as session:
            # User message
            user_msg = ConversationMessage(
                conversation_id=conversation_id,
                role="user",
                content=user_content,
                content_redacted=self.redact_content(user_content),
                risk_level=risk_info.get("level", "NONE"),
                risk_categories=risk_info.get("categories", []),
                risk_evidence=risk_info.get("evidence")
            )
            
            # Assistant message
            assistant_msg = ConversationMessage(
                conversation_id=conversation_id,
                role="assistant",
                content=assistant_content,
                content_redacted=self.redact_content(assistant_content),
                rag_sources=rag_sources,
                profile_snapshot=profile_snapshot
            )
            
            session.add_all([user_msg, assistant_msg])
            
            # 更新會話的 last_message_at
            await session.execute(
                update(Conversation)
                .where(Conversation.id == conversation_id)
                .values(
                    last_message_at=datetime.utcnow(),
                    updated_at=datetime.utcnow()
                )
            )
    
    def redact_content(self, content: str) -> str:
        """基礎脫敏 (實際實作見脫敏設計文件)"""
        # TODO: 實作脫敏邏輯
        return content[:200] + "..." if len(content) > 200 else content
```

## 資料庫維護

### 定期維護任務
```sql
-- 每日執行 VACUUM ANALYZE
VACUUM ANALYZE conversation_messages;

-- 每週重建索引
REINDEX INDEX CONCURRENTLY idx_msg_updated;

-- 每月建立新分區
CREATE TABLE conversation_messages_2025_02 PARTITION OF conversation_messages
FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');

-- 刪除舊分區 (保留3年)
DROP TABLE conversation_messages_2022_01;
```

### 備份策略
```bash
# 每日備份 (保留30天)
pg_dump -h localhost -U postgres -d xiongichat -f backup_$(date +%Y%m%d).sql

# 即時備份 (WAL archive)
archive_mode = on
archive_command = 'cp %p /backup/wal/%f'
```

## 效能優化檢查清單
- [ ] 所有外鍵都有索引
- [ ] updated_at 欄位都有降序索引
- [ ] 使用 EXPLAIN ANALYZE 檢查慢查詢
- [ ] 設定 connection pool 大小
- [ ] 啟用 pg_stat_statements 監控
- [ ] 定期執行 VACUUM 和 ANALYZE

## 關鍵記憶點
1. **絕對不要**忘記 updated_at 索引，這是增量同步的關鍵
2. **務必**實作資料表分區，避免單表過大
3. **記得**加密敏感資料，content 欄位需要應用層加密
4. **注意** pgvector 索引需要定期重建以保持效能