# 雄i聊系統 - 階段式開發計畫

## 開發順序總覽

基於現有設計文件，採用漸進式開發策略，從核心功能開始逐步擴展。

---

## 📘 第一階段：基礎聊天與短期記憶
**目標**：建立可對話的基本系統  
**預計時程**：1週  
**參考文件**：`03-LangGraph工作流設計.md`、`LangGraph設計.md`

### 詳細實作步驟

#### Day 1-2：資料庫與環境設置
1. **資料庫初始化**
   ```sql
   -- 建立資料庫
   CREATE DATABASE xiongichat;
   
   -- 建立基礎表
   CREATE TABLE conversations (...);
   CREATE TABLE conversation_messages (...);
   ```

2. **Python 環境設置**
   ```bash
   # 安裝必要套件
   pip install langgraph langchain openai sqlalchemy asyncpg
   ```

3. **配置檔案**
   - `.env` 環境變數
   - `config.yaml` 系統設定
   - `database.py` 資料庫連線

#### Day 3-4：LangGraph 工作流實作
1. **State 定義**
   ```python
   # state.py
   class WorkflowState(TypedDict):
       user_id: str
       conversation_id: Optional[UUID]
       input_text: str
       reply: str
       _memory: List[Dict]
   ```

2. **ChatAgent 節點**
   - 使用 GPT-4o 模型
   - 系統 prompt 設計
   - 回覆生成邏輯

3. **ConversationLogger 節點**
   - 儲存使用者訊息
   - 儲存 AI 回覆
   - 更新對話時間戳

4. **工作流組裝**
   ```python
   # graph.py
   workflow = StateGraph(WorkflowState)
   workflow.add_node("chat", chat_agent)
   workflow.add_node("logger", conversation_logger)
   ```

#### Day 5：記憶管理與API
1. **Checkpointer 設置**
   - SQLite/PostgreSQL checkpointer
   - 對話狀態保存

2. **記憶管理**
   - 載入最近10輪對話
   - 上下文壓縮策略

3. **FastAPI 端點**
   ```python
   @app.post("/chat")
   async def chat(request: ChatRequest):
       # 執行 LangGraph 工作流
       result = await workflow.ainvoke(request)
       return ChatResponse(result)
   ```

#### Day 6-7：測試與調整
1. **單元測試**
   - 節點功能測試
   - 資料庫操作測試

2. **整合測試**
   - 完整工作流測試
   - API 端點測試

3. **效能調整**
   - 回應時間優化
   - 記憶載入優化

### 驗收標準
- ✅ 可進行多輪對話
- ✅ 記得前10輪對話內容
- ✅ 對話正確儲存至資料庫
- ✅ 平均回應時間 < 2秒

---

## 📗 第二階段：RAG 知識庫檢索
**目標**：加入毒防服務知識檢索能力  
**預計時程**：1.5週  
**參考文件**：`08-RAG檢索設計.md`、`03-LangGraph工作流設計.md`

### 詳細實作步驟

#### Day 1-2：向量資料庫設置
1. **PGVector 安裝**
   ```sql
   CREATE EXTENSION vector;
   
   CREATE TABLE knowledge_embeddings (
       id UUID PRIMARY KEY,
       content TEXT,
       embedding vector(1536),
       metadata JSONB
   );
   ```

2. **向量索引建立**
   ```sql
   CREATE INDEX ON knowledge_embeddings 
   USING ivfflat (embedding vector_cosine_ops)
   WITH (lists = 100);
   ```

#### Day 3-4：知識資料處理
1. **資料收集**
   - 毒防服務資訊
   - 法律條文
   - 醫療資源
   - 常見問題

2. **文件切塊**
   ```python
   # chunker.py
   def chunk_document(text, chunk_size=500, overlap=50):
       # 切塊邏輯
       chunks = []
       # ...
       return chunks
   ```

3. **向量化處理**
   ```python
   # embeddings.py
   embeddings = OpenAIEmbeddings(
       model="text-embedding-3-small"
   )
   vectors = embeddings.embed_documents(chunks)
   ```

#### Day 5-6：LangGraph 整合
1. **Router 節點**
   - 使用 GPT-4o-mini
   - 判斷意圖分類
   - 決定是否需 RAG

2. **RAGRetriever 節點**
   - 向量檢索
   - 相似度計算
   - Top-K 選擇

3. **重排序機制**
   - 使用 GPT-4o-mini 或交叉編碼器
   - MMR 多樣性重排

#### Day 7-8：API 與管理介面
1. **檢索 API**
   ```python
   @app.post("/knowledge/search")
   async def search(query: str, k: int = 5):
       # 向量檢索
       results = await retriever.search(query, k)
       return results
   ```

2. **知識上傳**
   ```python
   @app.post("/knowledge/upload")
   async def upload(file: UploadFile):
       # 處理上傳檔案
       # 切塊、嵌入、儲存
       return {"status": "success"}
   ```

#### Day 9-10：測試與優化
1. **檢索品質測試**
   - 準確率測試
   - 召回率測試

2. **效能優化**
   - 檢索速度優化
   - 向量索引調整

### 驗收標準
- ✅ 正確判斷何時需要檢索
- ✅ 檢索結果相關性 > 90%
- ✅ 回覆中自然融入檢索資訊
- ✅ 檢索速度 < 500ms

---

## 📙 第三階段：風險偵測與通知
**目標**：實作高風險訊號偵測與記錄  
**預計時程**：1週  
**參考文件**：`07-風險偵測設計.md`、`LangGraph設計.md`

### 詳細實作步驟

#### Day 1-2：風險偵測機制
1. **規則庫建立**
   ```python
   RISK_KEYWORDS = {
       "self_harm": ["自殺", "自殘", "結束生命"],
       "drug_use": ["吸毒", "用藥", "海洛因"],
       "violence": ["打人", "傷害", "報復"]
   }
   ```

2. **RiskDetector 節點**
   - 第一層：規則檢測
   - 第二層：GPT-4o-mini 分類
   - 風險等級合併

3. **風險等級定義**
   - NONE: 無風險
   - LOW: 低風險
   - MEDIUM: 中風險
   - HIGH: 高風險
   - IMMINENT: 緊急風險

#### Day 3-4：資料儲存與記錄
1. **資料庫更新**
   ```sql
   ALTER TABLE conversation_messages 
   ADD COLUMN risk_level TEXT,
   ADD COLUMN risk_categories TEXT[];
   
   CREATE TABLE risk_events (
       id UUID PRIMARY KEY,
       user_id TEXT,
       message_id UUID,
       risk_level TEXT,
       detected_at TIMESTAMP
   );
   ```

2. **風險事件記錄**
   - 高風險自動記錄
   - 證據保存
   - 時間序列追蹤

#### Day 5：個案檔案管理
1. **Cases 表建立**
   ```sql
   CREATE TABLE cases (
       user_id TEXT PRIMARY KEY,
       nickname TEXT,
       lang TEXT,
       stage TEXT,
       goals JSONB
   );
   ```

2. **ProfileManager 節點**
   - 讀取個案資料
   - 更新個案狀態
   - 目標管理

#### Day 6：通知與報表
1. **基礎通知系統**
   - 記錄至資料庫
   - 管理界面查看

2. **風險報表**
   - 日報表生成
   - 統計視圖
   - 趨勢分析

#### Day 7：測試與驗證
1. **測試案例**
   - 各級風險測試
   - 誤報率測試
   - 漏報率測試

2. **效能調整**
   - 偵測速度優化
   - 規則優先級調整

### 驗收標準
- ✅ 風險偵測準確率 > 95%
- ✅ 風險分級正確（5級）
- ✅ 高風險事件正確記錄
- ✅ 個案檔案正常讀寫

---

## 🔐 第四階段：安全機制
**目標**：實作基本安全防護  
**預計時程**：1.5週  
**參考文件**：`04-安全機制設計.md`、`系統需求.md`

### 詳細實作步驟

#### Day 1-2：身份驗證與授權
1. **API Key 管理**
   ```python
   # auth/api_key.py
   def verify_api_key(api_key: str):
       # 驗證 API Key
       return client_info
   ```

2. **JWT 實作**
   ```python
   # auth/jwt_handler.py
   def create_token(client_id: str, scopes: List[str]):
       payload = {
           "client_id": client_id,
           "scopes": scopes,
           "exp": datetime.utcnow() + timedelta(hours=1)
       }
       return jwt.encode(payload, SECRET_KEY)
   ```

3. **OAuth2 Scopes**
   - conversations.read
   - messages.read
   - messages.read_full
   - profiles.read

#### Day 3-4：權限控制與審計
1. **RBAC 實作**
   ```python
   ROLES = {
       "admin": ["*"],
       "operator": ["messages.read", "conversations.read"],
       "viewer": ["conversations.read"]
   }
   ```

2. **審計日誌**
   ```sql
   CREATE TABLE audit_logs (
       id UUID PRIMARY KEY,
       client_id TEXT,
       action TEXT,
       resource TEXT,
       ip_address TEXT,
       timestamp TIMESTAMP,
       metadata JSONB
   );
   ```

3. **中間件實作**
   ```python
   @app.middleware("http")
   async def audit_middleware(request, call_next):
       # 記錄請求
       await log_request(request)
       response = await call_next(request)
       return response
   ```

#### Day 5-6：資料加密
1. **欄位加密**
   ```python
   # encryption/aes.py
   from cryptography.fernet import Fernet
   
   def encrypt_field(data: str) -> bytes:
       cipher = Fernet(KEY)
       return cipher.encrypt(data.encode())
   ```

2. **環境變數保護**
   - 使用 python-dotenv
   - 敏感資料不入版控

#### Day 7-9：同步 API
1. **Pull API 實作**
   ```python
   @app.get("/api/v1/conversations")
   async def get_conversations(
       updated_after: datetime,
       page_size: int = 500,
       cursor: str = None
   ):
       # 增量拉取邏輯
       return {
           "items": conversations,
           "next_cursor": next_cursor
       }
   ```

2. **游標實作**
   ```python
   def create_cursor(last_id: UUID, timestamp: datetime):
       # 加密游標
       data = f"{last_id}:{timestamp.isoformat()}"
       return base64.b64encode(data.encode())
   ```

3. **限流機制**
   ```python
   from slowapi import Limiter
   
   limiter = Limiter(
       key_func=get_client_id,
       default_limits=["5/second", "600/minute"]
   )
   ```

#### Day 10：測試與文檔
1. **安全測試**
   - 認證測試
   - 權限測試
   - 加密驗證

2. **API 文檔**
   - OpenAPI 規格
   - Swagger UI

### 驗收標準
- ✅ 所有 API 需要認證
- ✅ 審計日誌完整記錄
- ✅ 敏感資料已加密
- ✅ 同步 API 正常運作

---

## 🔒 第五階段：脫敏機制
**目標**：保護個人隱私資訊  
**預計時程**：1週  
**參考文件**：`05-脫敏機制設計.md`、`脫敏處理時機與流程.md`

### 詳細實作步驟

#### Day 1-2：脫敏引擎開發
1. **規則引擎**
   ```python
   # redaction/patterns.py
   PATTERNS = {
       "tw_id": r'\b[A-Z][12]\d{8}\b',
       "phone": r'\b09\d{8}\b',
       "email": r'\b[\w.-]+@[\w.-]+\.\w+\b'
   }
   ```

2. **NER 整合**
   ```python
   # 安裝 spaCy 中文模型
   import spacy
   nlp = spacy.load("zh_core_web_sm")
   ```

3. **脫敏結果**
   ```python
   def redact(text: str) -> RedactionResult:
       # 規則檢測
       # NER 檢測
       # 合併結果
       return RedactionResult(
           original=text,
           redacted=redacted_text,
           found_items=items
       )
   ```

#### Day 3-4：雙版本儲存
1. **資料庫更新**
   ```sql
   ALTER TABLE conversation_messages
   ADD COLUMN content_redacted TEXT,
   ADD COLUMN redaction_metadata JSONB;
   ```

2. **儲存流程**
   ```python
   async def save_message(content: str):
       # 脫敏處理
       result = redactor.redact(content)
       
       # 儲存雙版本
       await db.save({
           "content": encrypt(content),
           "content_redacted": result.redacted,
           "redaction_metadata": result.metadata
       })
   ```

#### Day 5：動態脫敏
1. **根據權限返回**
   ```python
   @app.get("/messages/{id}")
   async def get_message(
       id: UUID,
       include_content: bool = False,
       client = Depends(get_client)
   ):
       if include_content and "messages.read_full" in client.scopes:
           # 返回原文
           return {"content": decrypt(message.content)}
       else:
           # 返回脫敏版
           return {"content": message.content_redacted}
   ```

2. **日誌脫敏**
   ```python
   class RedactingLogger:
       def log(self, message: str):
           redacted = self.redactor.redact(message)
           logger.info(redacted.redacted)
   ```

#### Day 6：管理介面
1. **脫敏規則管理**
   - CRUD 介面
   - 熱更新機制

2. **效果預覽**
   ```python
   @app.post("/redaction/preview")
   async def preview(text: str):
       result = redactor.redact(text)
       return {
           "original": text,
           "redacted": result.redacted,
           "found": result.found_items
       }
   ```

#### Day 7：測試與驗證
1. **脫敏測試**
   - 各類 PII 測試
   - 語意保留測試
   - 效能測試

2. **權限驗證**
   - 原文存取測試
   - 審計記錄驗證

### 驗收標準
- ✅ PII 資訊 100% 脫敏
- ✅ 脫敏後仍保持語意
- ✅ 原文存取需特殊權限
- ✅ 脫敏速度 < 100ms/千字

---

## 🚀 部署與優化（持續進行）
**參考文件**：`09-部署與監控設計.md`

### 持續改進項目
- 效能優化（快取、索引）
- 監控告警（Prometheus、Grafana）
- 容器化部署（Docker、K8s）
- CI/CD 流程
- 壓力測試與調優

---

## 📊 時程總覽

| 階段 | 內容 | 預計時程 | 依賴 |
|-----|------|---------|------|
| 第一階段 | 聊天與記憶 | 1週 | - |
| 第二階段 | RAG知識庫 | 1.5週 | 第一階段 |
| 第三階段 | 風險偵測 | 1週 | 第一階段 |
| 第四階段 | 安全機制 | 1.5週 | 第三階段 |
| 第五階段 | 脫敏機制 | 1週 | 第四階段 |
| **總計** | **MVP版本** | **6週** | - |

## 💡 開發原則

1. **漸進式開發**：每階段都是可運行的系統
2. **文件驅動**：嚴格按照設計文件實作
3. **測試先行**：每階段都有明確驗收標準
4. **向後相容**：新功能不破壞既有功能
5. **模組化設計**：各階段功能可獨立開關

## 🎯 關鍵里程碑

- **Week 1**：基本聊天功能上線
- **Week 2.5**：知識檢索功能完成
- **Week 3.5**：風險偵測啟用
- **Week 5**：安全機制部署
- **Week 6**：脫敏功能完成，MVP版本交付

---

*註：實際開發時程可能因技術挑戰或需求變更而調整*