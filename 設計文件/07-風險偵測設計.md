# 07 - é¢¨éšªåµæ¸¬è¨­è¨ˆæ–‡ä»¶

## å¿«é€Ÿæ¢å¾©æŒ‡å—
å¦‚æœä½ å¿˜è¨˜äº†é€™å€‹æ¨¡çµ„ï¼Œè¨˜ä½ï¼šé€™æ˜¯ç³»çµ±çš„å®‰å…¨é˜²è­·ç¶²ï¼Œè² è²¬å³æ™‚åµæ¸¬è‡ªæ®ºã€æš´åŠ›ã€ç”¨è—¥ã€çŠ¯ç½ªç­‰é¢¨éšªè¨Šè™Ÿã€‚æ¡ç”¨è¦å‰‡+MLé›™å±¤æª¢æ¸¬ï¼Œæ”¯æ´å¤šèªè¨€ï¼Œä¸¦è§¸ç™¼ç›¸æ‡‰çš„å±æ©Ÿå¹²é æ©Ÿåˆ¶ã€‚

## æ ¸å¿ƒæŠ€è¡“æ£§
- Transformers (BERT/RoBERTa åˆ†é¡å™¨)
- scikit-learn (è¦å‰‡å¼•æ“)
- Redis (é¢¨éšªå¿«å–)
- PostgreSQL (é¢¨éšªäº‹ä»¶å­˜å„²)

## å°ˆæ¡ˆçµæ§‹
```
risk_detection/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ detector.py         # ä¸»åµæ¸¬å¼•æ“
â”œâ”€â”€ rules/              # è¦å‰‡å®šç¾©
â”‚   â”œâ”€â”€ keywords.yaml   # é—œéµå­—è¦å‰‡
â”‚   â”œâ”€â”€ patterns.yaml   # æ¨¡å¼è¦å‰‡
â”‚   â””â”€â”€ phrases.yaml    # ç‰‡èªè¦å‰‡
â”œâ”€â”€ models/             # ML æ¨¡å‹
â”‚   â”œâ”€â”€ risk_classifier.py
â”‚   â”œâ”€â”€ bert_zh/       # ä¸­æ–‡ BERT
â”‚   â””â”€â”€ roberta_en/    # è‹±æ–‡ RoBERTa
â”œâ”€â”€ handlers/           # é¢¨éšªè™•ç†å™¨
â”‚   â”œâ”€â”€ crisis.py      # å±æ©Ÿè™•ç†
â”‚   â”œâ”€â”€ notification.py # é€šçŸ¥æ©Ÿåˆ¶
â”‚   â””â”€â”€ intervention.py # å¹²é ç­–ç•¥
â””â”€â”€ analytics/          # é¢¨éšªåˆ†æ
    â”œâ”€â”€ trends.py      # è¶¨å‹¢åˆ†æ
    â””â”€â”€ reports.py     # å ±è¡¨ç”Ÿæˆ
```

## 1. é¢¨éšªç­‰ç´šå®šç¾©

```python
# risk_levels.py
from enum import Enum
from dataclasses import dataclass
from typing import List, Optional

class RiskLevel(Enum):
    """é¢¨éšªç­‰ç´š"""
    NONE = "NONE"           # ç„¡é¢¨éšª
    LOW = "LOW"             # ä½é¢¨éšª - éœ€è¦é—œæ³¨
    MEDIUM = "MEDIUM"       # ä¸­é¢¨éšª - éœ€è¦ä»‹å…¥
    HIGH = "HIGH"           # é«˜é¢¨éšª - ç«‹å³ä»‹å…¥
    IMMINENT = "IMMINENT"   # å±æ€¥ - ç·Šæ€¥è™•ç†

class RiskCategory(Enum):
    """é¢¨éšªé¡åˆ¥"""
    SELF_HARM = "self_harm"           # è‡ªæˆ‘å‚·å®³
    SUICIDE = "suicide"               # è‡ªæ®ºæ„å¿µ
    VIOLENCE = "violence"             # æš´åŠ›å‚¾å‘
    DRUG_USE = "drug_use"            # è—¥ç‰©ä½¿ç”¨
    DRUG_DEAL = "drug_deal"          # è—¥ç‰©äº¤æ˜“
    CRIME = "crime"                  # çŠ¯ç½ªæ„åœ–
    RELAPSE = "relapse"              # å¾©ç™¼é¢¨éšª
    MENTAL_HEALTH = "mental_health"  # å¿ƒç†å¥åº·
    SOCIAL_RISK = "social_risk"      # ç¤¾æœƒé¢¨éšª

@dataclass
class RiskIndicator:
    """é¢¨éšªæŒ‡æ¨™"""
    category: RiskCategory
    level: RiskLevel
    confidence: float  # 0.0 - 1.0
    evidence: List[str]
    recommended_action: Optional[str]
    
@dataclass
class RiskAssessment:
    """é¢¨éšªè©•ä¼°çµæœ"""
    overall_level: RiskLevel
    categories: List[RiskCategory]
    indicators: List[RiskIndicator]
    timestamp: datetime
    context: dict
    intervention_required: bool
    alert_sent: bool = False
```

## 2. é—œéµå­—è¦å‰‡å¼•æ“

```yaml
# rules/keywords.yaml
risk_keywords:
  suicide:
    high_risk:
      zh-TW:
        - æƒ³æ­»
        - ä¸æƒ³æ´»
        - çµæŸç”Ÿå‘½
        - è‡ªæ®º
        - è·³æ¨“
        - ä¸ŠåŠ
        - å‰²è…•
        - åƒå®‰çœ è—¥
        - éºæ›¸
      en:
        - kill myself
        - end my life
        - suicide
        - want to die
        - no reason to live
    
    medium_risk:
      zh-TW:
        - æ´»è‘—å¥½ç´¯
        - æ²’æœ‰æ„ç¾©
        - æ¶ˆå¤±
        - è§£è„«
        - é›¢é–‹é€™ä¸–ç•Œ
      en:
        - tired of living
        - meaningless
        - disappear
        - give up
    
  violence:
    high_risk:
      zh-TW:
        - æ®ºæ­»
        - å ±å¾©
        - å¼„æ­»ä»–
        - æ•™è¨“
        - æ‰“çˆ†
      en:
        - kill him
        - revenge
        - beat up
        - hurt them
    
  drug_use:
    high_risk:
      zh-TW:
        - æ³¨å°„
        - æ‰“è—¥
        - å¸æ¯’
        - å—‘è—¥
        - æ‹‰K
        - ç”¨å®‰
      en:
        - shoot up
        - using drugs
        - get high
        - meth
        - heroin
    
    medium_risk:
      zh-TW:
        - æƒ³ç”¨
        - æˆ’ä¸æ‰
        - è—¥é ­
        - è²¨
        - ç´”åº¦
      en:
        - craving
        - can't quit
        - dealer
        - stuff
        
  relapse:
    indicators:
      zh-TW:
        - å¥½æƒ³ç”¨
        - å—ä¸äº†äº†
        - å¿«æ’ä¸ä½
        - åˆé–‹å§‹æƒ³
        - å¿ƒç™¢
      en:
        - craving badly
        - can't resist
        - falling apart
        - tempted
```

```python
# detector.py
import re
import yaml
from typing import Dict, List, Tuple
from dataclasses import dataclass

class KeywordDetector:
    """é—œéµå­—åµæ¸¬å™¨"""
    
    def __init__(self, rules_path: str = "rules/keywords.yaml"):
        with open(rules_path, 'r', encoding='utf-8') as f:
            self.rules = yaml.safe_load(f)
        
        # ç·¨è­¯æ­£å‰‡è¡¨é”å¼
        self._compile_patterns()
    
    def _compile_patterns(self):
        """ç·¨è­¯é—œéµå­—ç‚ºæ­£å‰‡è¡¨é”å¼"""
        self.compiled_rules = {}
        
        for category, levels in self.rules['risk_keywords'].items():
            self.compiled_rules[category] = {}
            
            for level, languages in levels.items():
                self.compiled_rules[category][level] = {}
                
                for lang, keywords in languages.items():
                    # å»ºç«‹æ­£å‰‡è¡¨é”å¼ (å¿½ç•¥å¤§å°å¯«)
                    pattern = '|'.join(
                        re.escape(keyword) for keyword in keywords
                    )
                    self.compiled_rules[category][level][lang] = re.compile(
                        pattern,
                        re.IGNORECASE
                    )
    
    def detect(
        self,
        text: str,
        lang: str = "zh-TW"
    ) -> List[RiskIndicator]:
        """åµæ¸¬é¢¨éšªé—œéµå­—"""
        
        indicators = []
        
        for category, levels in self.compiled_rules.items():
            for level_name, languages in levels.items():
                if lang in languages:
                    pattern = languages[lang]
                    matches = pattern.findall(text)
                    
                    if matches:
                        # è¨ˆç®—é¢¨éšªç­‰ç´š
                        if level_name == "high_risk":
                            level = RiskLevel.HIGH
                            confidence = 0.9
                        elif level_name == "medium_risk":
                            level = RiskLevel.MEDIUM
                            confidence = 0.7
                        else:
                            level = RiskLevel.LOW
                            confidence = 0.5
                        
                        indicators.append(RiskIndicator(
                            category=RiskCategory(category),
                            level=level,
                            confidence=confidence,
                            evidence=[f"keyword:{m}" for m in matches[:3]],
                            recommended_action=self._get_action(category, level)
                        ))
        
        return indicators
    
    def _get_action(self, category: str, level: RiskLevel) -> str:
        """å–å¾—å»ºè­°è¡Œå‹•"""
        
        actions = {
            ("suicide", RiskLevel.HIGH): "ç«‹å³å•Ÿå‹•å±æ©Ÿå¹²é å”è­°ï¼Œæä¾›24å°æ™‚ç†±ç·š",
            ("suicide", RiskLevel.MEDIUM): "è¡¨é”é—œå¿ƒï¼Œè©•ä¼°é¢¨éšªï¼Œæä¾›æ”¯æŒè³‡æº",
            ("violence", RiskLevel.HIGH): "è©•ä¼°å¨è„…çœŸå¯¦æ€§ï¼Œå¿…è¦æ™‚é€šçŸ¥ç›¸é—œå–®ä½",
            ("drug_use", RiskLevel.HIGH): "æä¾›æˆ’æ²»è³‡æºï¼Œå®‰æ’ç·Šæ€¥è«®è©¢",
            ("relapse", RiskLevel.MEDIUM): "åŠ å¼·æ”¯æŒï¼Œå®‰æ’è«®è©¢å¸«ä»‹å…¥"
        }
        
        return actions.get((category, level), "æŒçºŒè§€å¯Ÿï¼Œæä¾›æ”¯æŒ")
```

## 3. ML é¢¨éšªåˆ†é¡å™¨

```python
# models/risk_classifier.py
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    pipeline
)
import torch
import numpy as np
from typing import Dict, List

class MLRiskClassifier:
    """æ©Ÿå™¨å­¸ç¿’é¢¨éšªåˆ†é¡å™¨"""
    
    def __init__(self, model_path: str = None):
        # è¼‰å…¥é è¨“ç·´æ¨¡å‹
        if model_path:
            self.model = AutoModelForSequenceClassification.from_pretrained(
                model_path
            )
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        else:
            # ä½¿ç”¨é è¨­æ¨¡å‹
            self._load_default_model()
        
        # å»ºç«‹ pipeline
        self.classifier = pipeline(
            "text-classification",
            model=self.model,
            tokenizer=self.tokenizer,
            device=0 if torch.cuda.is_available() else -1
        )
        
        # æ¨™ç±¤æ˜ å°„
        self.label_map = {
            "SAFE": RiskLevel.NONE,
            "LOW_RISK": RiskLevel.LOW,
            "MEDIUM_RISK": RiskLevel.MEDIUM,
            "HIGH_RISK": RiskLevel.HIGH,
            "CRISIS": RiskLevel.IMMINENT
        }
    
    def _load_default_model(self):
        """è¼‰å…¥é è¨­æ¨¡å‹"""
        # ä½¿ç”¨å¾®èª¿éçš„ BERT æ¨¡å‹
        model_name = "bert-base-chinese"  # æˆ–è‡ªè¨‚æ¨¡å‹
        
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=5  # 5å€‹é¢¨éšªç­‰ç´š
        )
        
        # å¦‚æœæœ‰æœ¬åœ°æ¬Šé‡æª”
        try:
            checkpoint = torch.load("models/risk_bert_checkpoint.pt")
            self.model.load_state_dict(checkpoint['model_state_dict'])
        except:
            pass
    
    def predict(self, text: str) -> Dict:
        """é æ¸¬é¢¨éšªç­‰ç´š"""
        
        # åŸ·è¡Œåˆ†é¡
        results = self.classifier(text, top_k=None)
        
        # è½‰æ›çµæœ
        predictions = {}
        for result in results:
            label = result['label']
            score = result['score']
            
            risk_level = self.label_map.get(label, RiskLevel.NONE)
            predictions[risk_level] = score
        
        # å–å¾—æœ€é«˜é¢¨éšª
        max_risk = max(predictions.items(), key=lambda x: x[1])
        
        return {
            "level": max_risk[0],
            "confidence": max_risk[1],
            "all_scores": predictions
        }
    
    def predict_batch(self, texts: List[str]) -> List[Dict]:
        """æ‰¹æ¬¡é æ¸¬"""
        
        results = []
        
        # æ‰¹æ¬¡è™•ç†æå‡æ•ˆç‡
        batch_size = 32
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            batch_results = self.classifier(batch, top_k=None)
            
            for j, text_results in enumerate(batch_results):
                predictions = {}
                for result in text_results:
                    label = result['label']
                    score = result['score']
                    risk_level = self.label_map.get(label, RiskLevel.NONE)
                    predictions[risk_level] = score
                
                max_risk = max(predictions.items(), key=lambda x: x[1])
                results.append({
                    "text": batch[j],
                    "level": max_risk[0],
                    "confidence": max_risk[1],
                    "all_scores": predictions
                })
        
        return results
```

## 4. ä¸Šä¸‹æ–‡æ„ŸçŸ¥åµæ¸¬

```python
# context_detector.py
from typing import List, Dict, Optional
from collections import deque

class ContextAwareDetector:
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥é¢¨éšªåµæ¸¬å™¨"""
    
    def __init__(self, window_size: int = 5):
        self.window_size = window_size
        self.conversation_history = {}  # {conversation_id: deque}
        self.user_profiles = {}  # {user_id: profile}
    
    def analyze_with_context(
        self,
        text: str,
        conversation_id: str,
        user_id: str,
        user_profile: Dict
    ) -> RiskAssessment:
        """çµåˆä¸Šä¸‹æ–‡åˆ†æé¢¨éšª"""
        
        # æ›´æ–°å°è©±æ­·å²
        if conversation_id not in self.conversation_history:
            self.conversation_history[conversation_id] = deque(
                maxlen=self.window_size
            )
        
        history = self.conversation_history[conversation_id]
        
        # åˆ†æç•¶å‰è¨Šæ¯
        current_indicators = self._analyze_current(text)
        
        # åˆ†ææ­·å²è¶¨å‹¢
        trend_indicators = self._analyze_trend(history, text)
        
        # åˆ†æä½¿ç”¨è€…é¢¨éšªå› å­
        profile_indicators = self._analyze_profile(user_profile)
        
        # ç¶œåˆè©•ä¼°
        assessment = self._combine_assessments(
            current_indicators,
            trend_indicators,
            profile_indicators
        )
        
        # æ›´æ–°æ­·å²
        history.append({
            "text": text,
            "assessment": assessment,
            "timestamp": datetime.utcnow()
        })
        
        return assessment
    
    def _analyze_current(self, text: str) -> List[RiskIndicator]:
        """åˆ†æç•¶å‰è¨Šæ¯"""
        
        indicators = []
        
        # æƒ…ç·’åˆ†æ
        emotion = self._detect_emotion(text)
        if emotion in ["despair", "anger", "hopeless"]:
            indicators.append(RiskIndicator(
                category=RiskCategory.MENTAL_HEALTH,
                level=RiskLevel.MEDIUM,
                confidence=0.7,
                evidence=[f"emotion:{emotion}"],
                recommended_action="æä¾›æƒ…ç·’æ”¯æŒ"
            ))
        
        # æ™‚é–“ç·Šè¿«æ€§
        urgency = self._detect_urgency(text)
        if urgency > 0.7:
            # æå‡æ‰€æœ‰é¢¨éšªç­‰ç´š
            for indicator in indicators:
                if indicator.level == RiskLevel.MEDIUM:
                    indicator.level = RiskLevel.HIGH
                elif indicator.level == RiskLevel.LOW:
                    indicator.level = RiskLevel.MEDIUM
        
        return indicators
    
    def _analyze_trend(
        self,
        history: deque,
        current_text: str
    ) -> List[RiskIndicator]:
        """åˆ†ææ­·å²è¶¨å‹¢"""
        
        if len(history) < 2:
            return []
        
        indicators = []
        
        # è¨ˆç®—é¢¨éšªå‡ç´šè¶¨å‹¢
        risk_scores = []
        for entry in history:
            assessment = entry.get("assessment")
            if assessment:
                # å°‡é¢¨éšªç­‰ç´šè½‰æ›ç‚ºæ•¸å€¼
                level_scores = {
                    RiskLevel.NONE: 0,
                    RiskLevel.LOW: 1,
                    RiskLevel.MEDIUM: 2,
                    RiskLevel.HIGH: 3,
                    RiskLevel.IMMINENT: 4
                }
                score = level_scores.get(assessment.overall_level, 0)
                risk_scores.append(score)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ä¸Šå‡è¶¨å‹¢
        if len(risk_scores) >= 3:
            recent_trend = risk_scores[-3:]
            if all(recent_trend[i] <= recent_trend[i+1] 
                   for i in range(len(recent_trend)-1)):
                # é¢¨éšªæŒçºŒä¸Šå‡
                indicators.append(RiskIndicator(
                    category=RiskCategory.MENTAL_HEALTH,
                    level=RiskLevel.HIGH,
                    confidence=0.8,
                    evidence=["escalating_risk_pattern"],
                    recommended_action="ç«‹å³ä»‹å…¥ï¼Œé¢¨éšªå‡ç´šä¸­"
                ))
        
        # æª¢æŸ¥é‡è¤‡å‡ºç¾çš„é¢¨éšªä¸»é¡Œ
        themes = self._extract_themes(history)
        if "suicide" in themes and themes["suicide"] >= 3:
            indicators.append(RiskIndicator(
                category=RiskCategory.SUICIDE,
                level=RiskLevel.HIGH,
                confidence=0.85,
                evidence=["persistent_suicide_ideation"],
                recommended_action="éœ€è¦å°ˆæ¥­å¿ƒç†è©•ä¼°"
            ))
        
        return indicators
    
    def _analyze_profile(self, profile: Dict) -> List[RiskIndicator]:
        """åˆ†æä½¿ç”¨è€…é¢¨éšªå› å­"""
        
        indicators = []
        
        # æª¢æŸ¥å¾©ç™¼é«˜é¢¨éšªæœŸ
        if profile.get("stage") == "treatment":
            days_in_treatment = profile.get("days_in_treatment", 0)
            
            # å‰30å¤©å’Œ90å¤©æ˜¯é«˜é¢¨éšªæœŸ
            if days_in_treatment <= 30:
                indicators.append(RiskIndicator(
                    category=RiskCategory.RELAPSE,
                    level=RiskLevel.MEDIUM,
                    confidence=0.6,
                    evidence=["early_treatment_stage"],
                    recommended_action="åŠ å¼·åˆæœŸæ”¯æŒ"
                ))
            elif 80 <= days_in_treatment <= 100:
                indicators.append(RiskIndicator(
                    category=RiskCategory.RELAPSE,
                    level=RiskLevel.MEDIUM,
                    confidence=0.65,
                    evidence=["90_day_milestone"],
                    recommended_action="é—œæ³¨90å¤©é—œå¡"
                ))
        
        # æª¢æŸ¥æ­·å²é¢¨éšªäº‹ä»¶
        risk_history = profile.get("risk_history", [])
        if risk_history:
            recent_events = [
                e for e in risk_history 
                if (datetime.utcnow() - e["timestamp"]).days <= 30
            ]
            
            if len(recent_events) >= 2:
                indicators.append(RiskIndicator(
                    category=RiskCategory.MENTAL_HEALTH,
                    level=RiskLevel.MEDIUM,
                    confidence=0.7,
                    evidence=["multiple_recent_risk_events"],
                    recommended_action="éœ€è¦å¯†åˆ‡é—œæ³¨"
                ))
        
        return indicators
    
    def _detect_emotion(self, text: str) -> str:
        """åµæ¸¬æƒ…ç·’"""
        # ç°¡åŒ–ç‰ˆæƒ…ç·’åµæ¸¬
        emotions = {
            "despair": ["çµ•æœ›", "æ²’å¸Œæœ›", "hopeless", "no hope"],
            "anger": ["ç”Ÿæ°£", "æ†¤æ€’", "æ¨", "angry", "hate"],
            "hopeless": ["ç„¡åŠ©", "æ²’ç”¨", "helpless", "useless"],
            "anxious": ["ç„¦æ…®", "ç·Šå¼µ", "å®³æ€•", "anxious", "scared"]
        }
        
        for emotion, keywords in emotions.items():
            if any(keyword in text.lower() for keyword in keywords):
                return emotion
        
        return "neutral"
    
    def _detect_urgency(self, text: str) -> float:
        """åµæ¸¬ç·Šè¿«æ€§"""
        
        urgent_phrases = [
            "ç¾åœ¨", "é¦¬ä¸Š", "ç«‹åˆ»", "ä»Šå¤©", "ç­‰ä¸åŠ",
            "now", "immediately", "today", "can't wait"
        ]
        
        urgent_count = sum(
            1 for phrase in urgent_phrases 
            if phrase in text.lower()
        )
        
        return min(urgent_count * 0.3, 1.0)
    
    def _extract_themes(self, history: deque) -> Dict[str, int]:
        """æå–ä¸»é¡Œ"""
        
        themes = {}
        
        for entry in history:
            assessment = entry.get("assessment")
            if assessment:
                for category in assessment.categories:
                    theme = category.value
                    themes[theme] = themes.get(theme, 0) + 1
        
        return themes
    
    def _combine_assessments(
        self,
        current: List[RiskIndicator],
        trend: List[RiskIndicator],
        profile: List[RiskIndicator]
    ) -> RiskAssessment:
        """ç¶œåˆè©•ä¼°"""
        
        all_indicators = current + trend + profile
        
        if not all_indicators:
            return RiskAssessment(
                overall_level=RiskLevel.NONE,
                categories=[],
                indicators=[],
                timestamp=datetime.utcnow(),
                context={},
                intervention_required=False
            )
        
        # å–æœ€é«˜é¢¨éšªç­‰ç´š
        max_level = max(
            indicator.level for indicator in all_indicators
        )
        
        # æ”¶é›†æ‰€æœ‰é¡åˆ¥
        categories = list(set(
            indicator.category for indicator in all_indicators
        ))
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦ä»‹å…¥
        intervention_required = (
            max_level in [RiskLevel.HIGH, RiskLevel.IMMINENT] or
            len([i for i in all_indicators if i.level >= RiskLevel.MEDIUM]) >= 3
        )
        
        return RiskAssessment(
            overall_level=max_level,
            categories=categories,
            indicators=all_indicators,
            timestamp=datetime.utcnow(),
            context={
                "has_trend": len(trend) > 0,
                "has_profile_risk": len(profile) > 0
            },
            intervention_required=intervention_required
        )
```

## 5. å±æ©Ÿè™•ç†æ©Ÿåˆ¶

```python
# handlers/crisis.py
from typing import Dict, List
import asyncio
from datetime import datetime

class CrisisHandler:
    """å±æ©Ÿè™•ç†å™¨"""
    
    def __init__(self, notification_service, db_helper):
        self.notification = notification_service
        self.db = db_helper
        
        # å±æ©Ÿè™•ç†å”è­°
        self.protocols = {
            RiskLevel.IMMINENT: self._handle_imminent_crisis,
            RiskLevel.HIGH: self._handle_high_risk,
            RiskLevel.MEDIUM: self._handle_medium_risk
        }
    
    async def handle(
        self,
        assessment: RiskAssessment,
        user_id: str,
        conversation_id: str
    ) -> Dict:
        """è™•ç†é¢¨éšªäº‹ä»¶"""
        
        # è¨˜éŒ„é¢¨éšªäº‹ä»¶
        event_id = await self._log_risk_event(
            assessment,
            user_id,
            conversation_id
        )
        
        # æ ¹æ“šé¢¨éšªç­‰ç´šåŸ·è¡Œå”è­°
        protocol = self.protocols.get(assessment.overall_level)
        
        if protocol:
            response = await protocol(
                assessment,
                user_id,
                conversation_id,
                event_id
            )
        else:
            response = {"action": "monitor", "notifications": []}
        
        # æ›´æ–°äº‹ä»¶ç‹€æ…‹
        await self._update_event_status(event_id, response)
        
        return response
    
    async def _handle_imminent_crisis(
        self,
        assessment: RiskAssessment,
        user_id: str,
        conversation_id: str,
        event_id: str
    ) -> Dict:
        """è™•ç†å±æ€¥æƒ…æ³"""
        
        actions = []
        
        # 1. ç«‹å³é€šçŸ¥å±æ©Ÿåœ˜éšŠ
        await self.notification.alert_crisis_team({
            "event_id": event_id,
            "user_id": user_id,
            "level": "IMMINENT",
            "categories": [c.value for c in assessment.categories],
            "timestamp": assessment.timestamp
        })
        actions.append("crisis_team_alerted")
        
        # 2. ç™¼é€ç·Šæ€¥è³‡æºçµ¦ä½¿ç”¨è€…
        crisis_resources = self._get_crisis_resources(assessment.categories)
        actions.append("resources_sent")
        
        # 3. å•Ÿå‹•24å°æ™‚ç›£æ§
        await self._activate_monitoring(user_id, duration_hours=24)
        actions.append("24h_monitoring_activated")
        
        # 4. é€šçŸ¥å€‹æ¡ˆç®¡ç†å¸«
        case_manager = await self._get_case_manager(user_id)
        if case_manager:
            await self.notification.notify_case_manager(
                case_manager,
                event_id,
                assessment
            )
            actions.append("case_manager_notified")
        
        return {
            "action": "crisis_intervention",
            "actions_taken": actions,
            "resources": crisis_resources,
            "follow_up_required": True,
            "monitoring_duration": 24
        }
    
    async def _handle_high_risk(
        self,
        assessment: RiskAssessment,
        user_id: str,
        conversation_id: str,
        event_id: str
    ) -> Dict:
        """è™•ç†é«˜é¢¨éšªæƒ…æ³"""
        
        actions = []
        
        # 1. é€šçŸ¥å€¼ç­è«®è©¢å¸«
        on_duty = await self._get_on_duty_counselor()
        if on_duty:
            await self.notification.notify_counselor(
                on_duty,
                event_id,
                assessment
            )
            actions.append("counselor_notified")
        
        # 2. æ’ç¨‹å¾ŒçºŒè¿½è¹¤
        follow_up = await self._schedule_follow_up(
            user_id,
            hours_later=4
        )
        actions.append(f"follow_up_scheduled:{follow_up}")
        
        # 3. åŠ å¼·æ”¯æŒè¨Šæ¯
        support_message = self._generate_support_message(assessment)
        actions.append("support_message_generated")
        
        return {
            "action": "high_risk_intervention",
            "actions_taken": actions,
            "support_message": support_message,
            "follow_up_required": True,
            "escalate_if_persist": True
        }
    
    async def _handle_medium_risk(
        self,
        assessment: RiskAssessment,
        user_id: str,
        conversation_id: str,
        event_id: str
    ) -> Dict:
        """è™•ç†ä¸­åº¦é¢¨éšª"""
        
        actions = []
        
        # 1. è¨˜éŒ„ä¸¦è¿½è¹¤
        await self._add_to_watchlist(user_id, assessment)
        actions.append("added_to_watchlist")
        
        # 2. æä¾›æ”¯æŒè³‡æº
        resources = self._get_support_resources(assessment.categories)
        actions.append("resources_provided")
        
        return {
            "action": "monitor_and_support",
            "actions_taken": actions,
            "resources": resources,
            "follow_up_required": False,
            "monitoring": "passive"
        }
    
    async def _log_risk_event(
        self,
        assessment: RiskAssessment,
        user_id: str,
        conversation_id: str
    ) -> str:
        """è¨˜éŒ„é¢¨éšªäº‹ä»¶"""
        
        event = {
            "id": str(uuid.uuid4()),
            "user_id": user_id,
            "conversation_id": conversation_id,
            "timestamp": assessment.timestamp,
            "risk_level": assessment.overall_level.value,
            "categories": [c.value for c in assessment.categories],
            "indicators": [
                {
                    "category": i.category.value,
                    "level": i.level.value,
                    "confidence": i.confidence,
                    "evidence": i.evidence
                }
                for i in assessment.indicators
            ],
            "intervention_required": assessment.intervention_required,
            "status": "new"
        }
        
        # å„²å­˜åˆ°è³‡æ–™åº«
        async with self.db.get_session() as session:
            session.add(RiskEvent(**event))
            await session.commit()
        
        # å¿«å–åˆ° Redis for å¿«é€ŸæŸ¥è©¢
        await self._cache_event(event)
        
        return event["id"]
    
    def _get_crisis_resources(
        self,
        categories: List[RiskCategory]
    ) -> Dict:
        """å–å¾—å±æ©Ÿè³‡æº"""
        
        resources = {
            "hotlines": [
                {"name": "ç”Ÿå‘½ç·š", "number": "1995", "available": "24/7"},
                {"name": "å¼µè€å¸«", "number": "1980", "available": "24/7"},
                {"name": "å®‰å¿ƒå°ˆç·š", "number": "1925", "available": "24/7"}
            ],
            "emergency": {
                "number": "119",
                "description": "ç·Šæ€¥é†«ç™‚æ•‘åŠ©"
            }
        }
        
        # æ ¹æ“šé¢¨éšªé¡åˆ¥åŠ å…¥ç‰¹å®šè³‡æº
        if RiskCategory.DRUG_USE in categories:
            resources["specialized"] = [
                {
                    "name": "æ¯’é˜²ä¸­å¿ƒ",
                    "number": "0800-770-885",
                    "description": "è—¥ç‰©æ¿«ç”¨è«®è©¢"
                }
            ]
        
        if RiskCategory.MENTAL_HEALTH in categories:
            resources["mental_health"] = [
                {
                    "name": "å¿ƒç†è¡›ç”Ÿä¸­å¿ƒ",
                    "description": "å°ˆæ¥­å¿ƒç†è«®å•†",
                    "booking": "ç·šä¸Šé ç´„"
                }
            ]
        
        return resources
    
    def _generate_support_message(
        self,
        assessment: RiskAssessment
    ) -> str:
        """ç”Ÿæˆæ”¯æŒè¨Šæ¯"""
        
        if RiskCategory.SUICIDE in assessment.categories:
            return """
æˆ‘è½åˆ°ä½ ç¾åœ¨å¾ˆç—›è‹¦ï¼Œé€™ä¸€å®šå¾ˆä¸å®¹æ˜“ã€‚
è«‹è¨˜å¾—ä½ ä¸¦ä¸å­¤å–®ï¼Œæˆ‘å€‘éƒ½åœ¨é€™è£¡æ”¯æŒä½ ã€‚

å¦‚æœä½ éœ€è¦ç«‹å³èˆ‡äººè«‡è«‡ï¼š
- ç”Ÿå‘½ç·šï¼š1995 (24å°æ™‚)
- å¼µè€å¸«ï¼š1980 (24å°æ™‚)

ä½ çš„ç”Ÿå‘½å¾ˆé‡è¦ï¼Œè®“æˆ‘å€‘ä¸€èµ·åº¦éé€™å€‹å›°é›£æ™‚æœŸã€‚
            """
        
        elif RiskCategory.RELAPSE in assessment.categories:
            return """
å¾©åŸçš„è·¯ä¸å®¹æ˜“ï¼Œæœ‰æƒ³è¦ä½¿ç”¨çš„å¿µé ­æ˜¯æ­£å¸¸çš„ã€‚
é€™ä¸ä»£è¡¨å¤±æ•—ï¼Œè€Œæ˜¯å¾©åŸéç¨‹çš„ä¸€éƒ¨åˆ†ã€‚

è©¦è©¦é€™äº›æ–¹æ³•ï¼š
- æ·±å‘¼å¸ï¼Œè®“å¿µé ­éå»
- æ‰“é›»è©±çµ¦æ”¯æŒä½ çš„äºº
- åšä¸€äº›è½‰ç§»æ³¨æ„åŠ›çš„æ´»å‹•

ä½ å·²ç¶“èµ°äº†é€™éº¼é ï¼Œæˆ‘ç›¸ä¿¡ä½ å¯ä»¥ç¹¼çºŒå …æŒã€‚
            """
        
        else:
            return """
æˆ‘æ³¨æ„åˆ°ä½ å¯èƒ½æ­£åœ¨ç¶“æ­·ä¸€äº›å›°é›£ã€‚
è«‹è¨˜å¾—ï¼Œå°‹æ±‚å¹«åŠ©æ˜¯å‹‡æ•¢çš„è¡¨ç¾ã€‚

æˆ‘å€‘çš„åœ˜éšŠéš¨æ™‚æº–å‚™æ”¯æŒä½ ã€‚
å¦‚æœä½ æƒ³è«‡è«‡ï¼Œæˆ‘å€‘éƒ½åœ¨é€™è£¡å‚¾è½ã€‚
            """
```

## 6. é€šçŸ¥èˆ‡å‘Šè­¦

```python
# handlers/notification.py
from typing import Dict, List
import aiohttp
import smtplib
from email.mime.text import MIMEText

class NotificationService:
    """é€šçŸ¥æœå‹™"""
    
    def __init__(self, config: dict):
        self.config = config
        self.channels = {
            "sms": self._send_sms,
            "email": self._send_email,
            "line": self._send_line,
            "slack": self._send_slack,
            "webhook": self._send_webhook
        }
    
    async def alert_crisis_team(self, event: Dict):
        """é€šçŸ¥å±æ©Ÿåœ˜éšŠ"""
        
        message = self._format_crisis_alert(event)
        
        # å¤šé€šé“é€šçŸ¥ç¢ºä¿é€é”
        tasks = []
        
        # SMS çµ¦å€¼ç­äººå“¡
        on_duty = await self._get_on_duty_staff()
        for staff in on_duty:
            tasks.append(
                self._send_sms(staff["phone"], message["sms"])
            )
        
        # Slack é€šçŸ¥åœ˜éšŠé »é“
        tasks.append(
            self._send_slack("#crisis-response", message["detailed"])
        )
        
        # Email çµ¦ä¸»ç®¡
        supervisors = await self._get_supervisors()
        for supervisor in supervisors:
            tasks.append(
                self._send_email(
                    supervisor["email"],
                    "ğŸš¨ å±æ©Ÿäº‹ä»¶é€šçŸ¥",
                    message["detailed"]
                )
            )
        
        # åŸ·è¡Œæ‰€æœ‰é€šçŸ¥
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è¨˜éŒ„é€šçŸ¥çµæœ
        await self._log_notifications(event["event_id"], results)
        
        return {
            "sent": len([r for r in results if not isinstance(r, Exception)]),
            "failed": len([r for r in results if isinstance(r, Exception)])
        }
    
    async def _send_sms(self, phone: str, message: str):
        """ç™¼é€ç°¡è¨Š"""
        
        # ä½¿ç”¨ Twilio æˆ–å…¶ä»– SMS æœå‹™
        async with aiohttp.ClientSession() as session:
            url = "https://api.twilio.com/2010-04-01/Accounts/{}/Messages.json"
            
            data = {
                "From": self.config["twilio"]["from_number"],
                "To": phone,
                "Body": message
            }
            
            auth = aiohttp.BasicAuth(
                self.config["twilio"]["account_sid"],
                self.config["twilio"]["auth_token"]
            )
            
            async with session.post(url, data=data, auth=auth) as resp:
                return await resp.json()
    
    async def _send_line(self, user_id: str, message: str):
        """ç™¼é€ LINE è¨Šæ¯"""
        
        headers = {
            "Authorization": f"Bearer {self.config['line']['channel_token']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "to": user_id,
            "messages": [
                {
                    "type": "text",
                    "text": message
                }
            ]
        }
        
        async with aiohttp.ClientSession() as session:
            url = "https://api.line.me/v2/bot/message/push"
            
            async with session.post(
                url,
                json=data,
                headers=headers
            ) as resp:
                return await resp.json()
    
    async def _send_slack(self, channel: str, message: str):
        """ç™¼é€ Slack è¨Šæ¯"""
        
        webhook_url = self.config["slack"]["webhook_url"]
        
        data = {
            "channel": channel,
            "text": message,
            "username": "é¢¨éšªåµæ¸¬ç³»çµ±",
            "icon_emoji": ":warning:"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(webhook_url, json=data) as resp:
                return await resp.text()
    
    def _format_crisis_alert(self, event: Dict) -> Dict:
        """æ ¼å¼åŒ–å±æ©Ÿå‘Šè­¦"""
        
        # ç°¡çŸ­ç‰ˆ (SMS)
        sms = f"ğŸš¨å±æ©Ÿäº‹ä»¶ #{event['event_id'][:8]}\nç”¨æˆ¶:{event['user_id']}\nç­‰ç´š:{event['level']}\nè«‹ç«‹å³è™•ç†"
        
        # è©³ç´°ç‰ˆ (Email/Slack)
        detailed = f"""
ğŸš¨ å±æ©Ÿäº‹ä»¶é€šçŸ¥
================
äº‹ä»¶ID: {event['event_id']}
ä½¿ç”¨è€…: {event['user_id']}
é¢¨éšªç­‰ç´š: {event['level']}
é¢¨éšªé¡åˆ¥: {', '.join(event['categories'])}
æ™‚é–“: {event['timestamp']}

è«‹ç«‹å³ç™»å…¥ç³»çµ±æŸ¥çœ‹è©³æƒ…ä¸¦æ¡å–è¡Œå‹•ã€‚
ç³»çµ±é€£çµ: {self.config['system_url']}/crisis/{event['event_id']}
        """
        
        return {
            "sms": sms,
            "detailed": detailed
        }
```

## 7. é¢¨éšªåˆ†æèˆ‡å ±è¡¨

```python
# analytics/trends.py
from typing import Dict, List
import pandas as pd
from datetime import datetime, timedelta

class RiskAnalytics:
    """é¢¨éšªåˆ†æ"""
    
    def __init__(self, db_helper):
        self.db = db_helper
    
    async def analyze_user_trends(
        self,
        user_id: str,
        days: int = 30
    ) -> Dict:
        """åˆ†æä½¿ç”¨è€…é¢¨éšªè¶¨å‹¢"""
        
        # æŸ¥è©¢æ­·å²é¢¨éšªäº‹ä»¶
        events = await self._get_user_risk_events(user_id, days)
        
        if not events:
            return {
                "trend": "no_data",
                "risk_score": 0,
                "recommendations": []
            }
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(events)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        # è¨ˆç®—è¶¨å‹¢
        analysis = {
            "total_events": len(events),
            "by_level": df['risk_level'].value_counts().to_dict(),
            "by_category": self._flatten_categories(df['categories']),
            "trend": self._calculate_trend(df),
            "peak_times": self._find_peak_times(df),
            "risk_score": self._calculate_risk_score(df),
            "patterns": self._identify_patterns(df)
        }
        
        # ç”¢ç”Ÿå»ºè­°
        analysis["recommendations"] = self._generate_recommendations(analysis)
        
        return analysis
    
    def _calculate_trend(self, df: pd.DataFrame) -> str:
        """è¨ˆç®—è¶¨å‹¢"""
        
        if len(df) < 2:
            return "insufficient_data"
        
        # å°‡é¢¨éšªç­‰ç´šè½‰ç‚ºæ•¸å€¼
        level_map = {
            "NONE": 0, "LOW": 1, "MEDIUM": 2,
            "HIGH": 3, "IMMINENT": 4
        }
        
        df['risk_score'] = df['risk_level'].map(level_map)
        
        # è¨ˆç®—ç§»å‹•å¹³å‡
        df['ma7'] = df['risk_score'].rolling(window=7, min_periods=1).mean()
        
        # æ¯”è¼ƒæœ€è¿‘7å¤©èˆ‡ä¹‹å‰7å¤©
        if len(df) >= 14:
            recent = df['risk_score'][-7:].mean()
            previous = df['risk_score'][-14:-7].mean()
            
            if recent > previous * 1.2:
                return "increasing"
            elif recent < previous * 0.8:
                return "decreasing"
            else:
                return "stable"
        else:
            return "stable"
    
    def _find_peak_times(self, df: pd.DataFrame) -> Dict:
        """æ‰¾å‡ºé«˜é¢¨éšªæ™‚æ®µ"""
        
        # æŒ‰å°æ™‚åˆ†çµ„
        df['hour'] = df.index.hour
        hourly = df.groupby('hour').size()
        
        # æŒ‰æ˜ŸæœŸåˆ†çµ„
        df['dayofweek'] = df.index.dayofweek
        daily = df.groupby('dayofweek').size()
        
        return {
            "peak_hours": hourly.nlargest(3).index.tolist(),
            "peak_days": daily.nlargest(2).index.tolist()
        }
    
    def _identify_patterns(self, df: pd.DataFrame) -> List[str]:
        """è­˜åˆ¥é¢¨éšªæ¨¡å¼"""
        
        patterns = []
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é€±æœŸæ€§
        if len(df) >= 7:
            # æª¢æŸ¥æ¯é€±æ¨¡å¼
            weekly_pattern = df.resample('W').size()
            if weekly_pattern.std() < weekly_pattern.mean() * 0.3:
                patterns.append("weekly_pattern")
        
        # æª¢æŸ¥è§¸ç™¼å› å­
        categories = self._flatten_categories(df['categories'])
        
        if categories.get("relapse", 0) > len(df) * 0.3:
            patterns.append("relapse_risk")
        
        if categories.get("suicide", 0) > 0:
            patterns.append("suicide_risk")
        
        # æª¢æŸ¥å‡ç´šæ¨¡å¼
        high_risk_events = df[df['risk_level'].isin(['HIGH', 'IMMINENT'])]
        if len(high_risk_events) > len(df) * 0.2:
            patterns.append("frequent_crisis")
        
        return patterns
    
    def _calculate_risk_score(self, df: pd.DataFrame) -> float:
        """è¨ˆç®—ç¶œåˆé¢¨éšªåˆ†æ•¸ (0-100)"""
        
        level_weights = {
            "NONE": 0, "LOW": 10, "MEDIUM": 30,
            "HIGH": 60, "IMMINENT": 100
        }
        
        # åŸºç¤åˆ†æ•¸
        base_score = df['risk_level'].map(level_weights).mean()
        
        # é »ç‡èª¿æ•´
        frequency_factor = min(len(df) / 30, 1.5)  # æœ€å¤š1.5å€
        
        # è¶¨å‹¢èª¿æ•´
        trend = self._calculate_trend(df)
        trend_factor = {
            "increasing": 1.2,
            "stable": 1.0,
            "decreasing": 0.8,
            "insufficient_data": 1.0
        }.get(trend, 1.0)
        
        # è¨ˆç®—æœ€çµ‚åˆ†æ•¸
        final_score = base_score * frequency_factor * trend_factor
        
        return min(100, max(0, final_score))
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """ç”¢ç”Ÿå»ºè­°"""
        
        recommendations = []
        
        # åŸºæ–¼è¶¨å‹¢
        if analysis["trend"] == "increasing":
            recommendations.append("åŠ å¼·ç›£æ§é »ç‡ï¼Œè€ƒæ…®ä¸»å‹•ä»‹å…¥")
        elif analysis["trend"] == "decreasing":
            recommendations.append("ç¶­æŒç¾æœ‰æ”¯æŒç­–ç•¥ï¼ŒæŒçºŒè§€å¯Ÿ")
        
        # åŸºæ–¼æ¨¡å¼
        patterns = analysis.get("patterns", [])
        
        if "suicide_risk" in patterns:
            recommendations.append("å®‰æ’å°ˆæ¥­å¿ƒç†è©•ä¼°")
            recommendations.append("ç¢ºä¿24å°æ™‚å±æ©Ÿæ”¯æ´å¯åŠæ€§")
        
        if "relapse_risk" in patterns:
            recommendations.append("åŠ å¼·æˆ’ç™®æ”¯æŒå°çµ„åƒèˆ‡")
            recommendations.append("è©•ä¼°è—¥ç‰©æ²»ç™‚æ–¹æ¡ˆ")
        
        if "frequent_crisis" in patterns:
            recommendations.append("è€ƒæ…®ä½é™¢æˆ–å¯†é›†é–€è¨ºæ²»ç™‚")
            recommendations.append("å»ºç«‹å±æ©Ÿæ‡‰è®Šè¨ˆåŠƒ")
        
        # åŸºæ–¼é¢¨éšªåˆ†æ•¸
        risk_score = analysis["risk_score"]
        
        if risk_score > 70:
            recommendations.append("ç«‹å³å®‰æ’å€‹æ¡ˆæœƒè­°")
        elif risk_score > 40:
            recommendations.append("å¢åŠ è«®è©¢é »ç‡")
        
        # åŸºæ–¼é«˜é¢¨éšªæ™‚æ®µ
        peak_hours = analysis.get("peak_times", {}).get("peak_hours", [])
        if peak_hours:
            recommendations.append(
                f"åœ¨é«˜é¢¨éšªæ™‚æ®µåŠ å¼·æ”¯æŒ: {peak_hours}"
            )
        
        return recommendations
```

## 8. æ¸¬è©¦èˆ‡é©—è­‰

```python
# test_risk_detection.py
import unittest
from datetime import datetime

class TestRiskDetection(unittest.TestCase):
    
    def setUp(self):
        self.keyword_detector = KeywordDetector()
        self.ml_classifier = MLRiskClassifier()
        self.context_detector = ContextAwareDetector()
    
    def test_suicide_keyword_detection(self):
        """æ¸¬è©¦è‡ªæ®ºé—œéµå­—åµæ¸¬"""
        
        test_cases = [
            ("æˆ‘æƒ³çµæŸè‡ªå·±çš„ç”Ÿå‘½", RiskLevel.HIGH),
            ("æ´»è‘—å¥½ç´¯ï¼Œä¸æƒ³ç¹¼çºŒäº†", RiskLevel.MEDIUM),
            ("ä»Šå¤©å¿ƒæƒ…ä¸å¤ªå¥½", RiskLevel.NONE)
        ]
        
        for text, expected_level in test_cases:
            indicators = self.keyword_detector.detect(text, "zh-TW")
            
            if expected_level == RiskLevel.NONE:
                self.assertEqual(len(indicators), 0)
            else:
                self.assertTrue(len(indicators) > 0)
                max_level = max(i.level for i in indicators)
                self.assertEqual(max_level, expected_level)
    
    def test_ml_classification(self):
        """æ¸¬è©¦ ML åˆ†é¡å™¨"""
        
        text = "æˆ‘çœŸçš„æ’ä¸ä¸‹å»äº†ï¼Œæƒ³è¦ä¸€äº†ç™¾äº†"
        result = self.ml_classifier.predict(text)
        
        self.assertIn(result["level"], [RiskLevel.HIGH, RiskLevel.IMMINENT])
        self.assertGreater(result["confidence"], 0.7)
    
    def test_context_awareness(self):
        """æ¸¬è©¦ä¸Šä¸‹æ–‡æ„ŸçŸ¥"""
        
        # æ¨¡æ“¬å°è©±æ­·å²
        conversation_id = "test_conv_1"
        user_id = "test_user_1"
        
        # ç¬¬ä¸€å‰‡è¨Šæ¯ - ä½é¢¨éšª
        assessment1 = self.context_detector.analyze_with_context(
            "æˆ‘ä»Šå¤©æ„Ÿè¦ºæœ‰é»ä½è½",
            conversation_id,
            user_id,
            {"stage": "treatment", "days_in_treatment": 15}
        )
        
        self.assertEqual(assessment1.overall_level, RiskLevel.LOW)
        
        # ç¬¬äºŒå‰‡è¨Šæ¯ - é¢¨éšªå‡ç´š
        assessment2 = self.context_detector.analyze_with_context(
            "è¶Šä¾†è¶Šç³Ÿäº†ï¼Œæˆ‘ä¸çŸ¥é“é‚„èƒ½æ’å¤šä¹…",
            conversation_id,
            user_id,
            {"stage": "treatment", "days_in_treatment": 15}
        )
        
        # æ‡‰è©²åµæ¸¬åˆ°å‡ç´šè¶¨å‹¢
        self.assertGreaterEqual(
            assessment2.overall_level.value,
            assessment1.overall_level.value
        )
    
    def test_crisis_handling(self):
        """æ¸¬è©¦å±æ©Ÿè™•ç†"""
        
        # æ¨¡æ“¬é«˜é¢¨éšªè©•ä¼°
        assessment = RiskAssessment(
            overall_level=RiskLevel.IMMINENT,
            categories=[RiskCategory.SUICIDE],
            indicators=[
                RiskIndicator(
                    category=RiskCategory.SUICIDE,
                    level=RiskLevel.IMMINENT,
                    confidence=0.95,
                    evidence=["keyword:è‡ªæ®º"],
                    recommended_action="ç«‹å³ä»‹å…¥"
                )
            ],
            timestamp=datetime.utcnow(),
            context={},
            intervention_required=True
        )
        
        handler = CrisisHandler(None, None)
        
        # æ¸¬è©¦è³‡æºç”Ÿæˆ
        resources = handler._get_crisis_resources([RiskCategory.SUICIDE])
        
        self.assertIn("hotlines", resources)
        self.assertIn("emergency", resources)
        self.assertTrue(len(resources["hotlines"]) > 0)
    
    def test_multilingual_detection(self):
        """æ¸¬è©¦å¤šèªè¨€æ”¯æ´"""
        
        test_cases = [
            ("I want to kill myself", "en", RiskLevel.HIGH),
            ("æˆ‘æƒ³è‡ªæ®º", "zh-TW", RiskLevel.HIGH),
            ("TÃ´i muá»‘n tá»± tá»­", "vi", RiskLevel.HIGH)  # è¶Šå—èª
        ]
        
        for text, lang, expected_level in test_cases:
            indicators = self.keyword_detector.detect(text, lang)
            # å¯¦éš›å¯¦ä½œéœ€è¦æ”¯æ´å¤šèªè¨€
            pass

if __name__ == "__main__":
    unittest.main()
```

## é—œéµè¨˜æ†¶é»
1. **å¿…é ˆ**å¯¦ä½œé›™å±¤æª¢æ¸¬ (è¦å‰‡+ML) ç¢ºä¿æº–ç¢ºæ€§
2. **è¨˜å¾—**è€ƒæ…®ä¸Šä¸‹æ–‡å’Œæ­·å²è¶¨å‹¢
3. **æ³¨æ„**ä¸åŒé¢¨éšªç­‰ç´šéœ€è¦ä¸åŒè™•ç†å”è­°
4. **é‡è¦**é«˜é¢¨éšªäº‹ä»¶å¿…é ˆå³æ™‚é€šçŸ¥ä¸”å¤šé€šé“ç¢ºä¿é€é”