"""æ¸¬è©¦ä¿®æ”¹å¾Œçš„è‡ªç„¶å°è©±æµç¨‹ - é¿å…éåº¦æä¾›è¯çµ¡è³‡è¨Š"""

import asyncio
import json
from uuid import uuid4
from app.langgraph.ultimate_workflow import UltimateWorkflow

async def test_natural_conversation_flow():
    """æ¸¬è©¦è‡ªç„¶å°è©±æµç¨‹ï¼Œç¢ºä¿ä¸éåº¦æä¾›è¯çµ¡è³‡è¨Š"""
    
    user_id = "natural_test"
    conversation_id = str(uuid4())
    workflow = UltimateWorkflow()
    
    print("ğŸ§ª æ¸¬è©¦ä¿®æ”¹å¾Œçš„è‡ªç„¶å°è©±æµç¨‹")
    print("=" * 60)
    
    # æ¸¬è©¦å ´æ™¯ï¼šå¾æƒ…ç·’å›°æ“¾åˆ°é€æ¼¸å¥½è½‰ï¼Œè§€å¯ŸAIæ˜¯å¦é©ç•¶æ§åˆ¶è³‡æºæä¾›
    test_scenarios = [
        {
            "stage": "åˆå§‹æƒ…ç·’å›°æ“¾",
            "input": "æˆ‘ä»Šå¤©å¿ƒæƒ…å¾ˆä¸å¥½ï¼Œè¦ºå¾—å¾ˆç´¯",
            "expected_behavior": "æ‡‰è©²æä¾›æƒ…ç·’æ”¯æŒï¼Œä¸æ‡‰ä¸»å‹•æä¾›è¯çµ¡è³‡è¨Š",
            "expected_rag": False
        },
        {
            "stage": "ç¹¼çºŒè¡¨é”å›°æ“¾", 
            "input": "æ„Ÿè¦ºç”Ÿæ´»æ²’ä»€éº¼æ„æ€ï¼Œæ¯å¤©éƒ½å¾ˆç—›è‹¦",
            "expected_behavior": "æ‡‰è©²å‡ç´šé—œæ‡·ç­–ç•¥ï¼Œä½†ä»ä¸æ‡‰ä¸»å‹•æ¨é€è¯çµ¡è³‡è¨Š",
            "expected_rag": False
        },
        {
            "stage": "è¡¨é”éœ€è¦å¹«åŠ©",
            "input": "æˆ‘è¦ºå¾—æˆ‘éœ€è¦æ‰¾äººèŠèŠï¼Œæœ‰ä»€éº¼åœ°æ–¹å¯ä»¥å¹«åŠ©æˆ‘å—ï¼Ÿ",
            "expected_behavior": "ç”¨æˆ¶ä¸»å‹•è©¢å•ï¼Œæ­¤æ™‚å¯ä»¥æä¾›è³‡æº",
            "expected_rag": True
        },
        {
            "stage": "æƒ…ç·’ç·©å’Œ",
            "input": "è¬è¬ä½ çš„å»ºè­°ï¼Œæˆ‘æ„Ÿè¦ºå¥½ä¸€é»äº†",
            "expected_behavior": "æƒ…ç·’æ”¹å–„ï¼Œä¸éœ€è¦å†æ¨é€è³‡æº",
            "expected_rag": False
        },
        {
            "stage": "ä¸€èˆ¬å°è©±",
            "input": "ä»Šå¤©å¤©æ°£ä¸éŒ¯å‘¢",
            "expected_behavior": "è¼•é¬†å°è©±ï¼Œçµ•å°ä¸æ‡‰æä¾›è¯çµ¡è³‡è¨Š",
            "expected_rag": False
        }
    ]
    
    results = []
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ“ {i}. {scenario['stage']}")
        print("-" * 40)
        print(f"ç”¨æˆ¶è¼¸å…¥: \"{scenario['input']}\"")
        
        test_input = {
            "user_id": user_id,
            "conversation_id": conversation_id,
            "input_text": scenario['input']
        }
        
        # åŸ·è¡Œå·¥ä½œæµ
        result = await workflow.ainvoke(test_input)
        
        # å–å¾—åˆ†æçµæœ
        intent_analysis = result.get('intent_analysis', {})
        actual_rag = intent_analysis.get('need_rag', False)
        risk_level = intent_analysis.get('risk_level', 'unknown')
        care_stage = intent_analysis.get('care_stage_needed', 1)
        
        # å–å¾—AIå›æ‡‰
        ai_response = result.get('reply', '')
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«è¯çµ¡è³‡è¨Š
        contains_contact = "072865580" in ai_response or "é«˜é›„å¸‚æ¯’å“é˜²åˆ¶å±€" in ai_response
        
        # è©•ä¼°çµæœ
        rag_correct = (actual_rag == scenario['expected_rag'])
        appropriate_response = not (contains_contact and not scenario['expected_rag'])
        
        status = "âœ…" if (rag_correct and appropriate_response) else "âŒ"
        
        print(f"{status} AIå›æ‡‰: \"{ai_response}\"")
        print(f"   RAGè§¸ç™¼: {actual_rag} (é æœŸ: {scenario['expected_rag']}) {'âœ…' if rag_correct else 'âŒ'}")
        print(f"   åŒ…å«è¯çµ¡è³‡è¨Š: {contains_contact} {'âœ…' if appropriate_response else 'âŒ'}")
        print(f"   é¢¨éšªç­‰ç´š: {risk_level} | é—œæ‡·éšæ®µ: {care_stage}")
        
        results.append({
            "stage": scenario['stage'],
            "input": scenario['input'],
            "response": ai_response,
            "expected_rag": scenario['expected_rag'],
            "actual_rag": actual_rag,
            "contains_contact": contains_contact,
            "rag_correct": rag_correct,
            "appropriate_response": appropriate_response,
            "risk_level": risk_level,
            "care_stage": care_stage
        })
        
        await asyncio.sleep(0.5)  # é¿å…éå¿«è«‹æ±‚
    
    # ç¸½çµè©•ä¼°
    print("\n" + "=" * 60)
    print("ğŸ“Š è‡ªç„¶å°è©±æµç¨‹æ¸¬è©¦ç¸½çµ")
    print("=" * 60)
    
    rag_accuracy = sum(1 for r in results if r['rag_correct']) / len(results) * 100
    response_appropriateness = sum(1 for r in results if r['appropriate_response']) / len(results) * 100
    
    print(f"\nğŸ¯ RAGè§¸ç™¼æº–ç¢ºç‡: {rag_accuracy:.1f}%")
    print(f"ğŸ¯ å›æ‡‰é©ç•¶æ€§: {response_appropriateness:.1f}%")
    
    # å•é¡Œåˆ†æ
    print("\nğŸ” è©³ç´°åˆ†æ:")
    for i, result in enumerate(results, 1):
        problems = []
        if not result['rag_correct']:
            problems.append(f"RAGè§¸ç™¼éŒ¯èª¤(é æœŸ:{result['expected_rag']}, å¯¦éš›:{result['actual_rag']})")
        if not result['appropriate_response']:
            problems.append("ä¸é©ç•¶åœ°æä¾›è¯çµ¡è³‡è¨Š")
        
        if problems:
            print(f"  {i}. {result['stage']}: {', '.join(problems)}")
        else:
            print(f"  {i}. {result['stage']}: æ­£å¸¸ âœ…")
    
    # æ”¹å–„å»ºè­°
    if rag_accuracy < 100 or response_appropriateness < 100:
        print("\nğŸ’¡ æ”¹å–„å»ºè­°:")
        if rag_accuracy < 100:
            print("  - RAGè§¸ç™¼é‚è¼¯éœ€è¦é€²ä¸€æ­¥èª¿æ•´")
        if response_appropriateness < 100:
            print("  - è³‡æºæä¾›çš„æ¢ä»¶åˆ¤æ–·éœ€è¦æ›´åš´æ ¼")
    else:
        print("\nğŸ† æ¸¬è©¦é€šéï¼å°è©±æµç¨‹å·²é”åˆ°è‡ªç„¶äº’å‹•æ¨™æº–")

if __name__ == "__main__":
    asyncio.run(test_natural_conversation_flow())